{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version is  2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "print(\"TensorFlow version is \", tf.__version__)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training class 0 images: 1264\n",
      "Total training class 1 images: 259\n",
      "Total training class 2 images: 699\n",
      "Total training class 3 images: 135\n",
      "Total training class 4 images: 207\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/Users/lucywang/Documents/Stanford/CS230Project/data_preproc'\n",
    "train_dir = os.path.join(base_dir, 'train_images_pre')\n",
    "dev_dir = os.path.join(base_dir, 'dev_images_pre')\n",
    "test_dir = os.path.join(base_dir, 'test_images_pre')\n",
    "\n",
    "train_0_dir = os.path.join(train_dir, '0')\n",
    "print ('Total training class 0 images:', len(os.listdir(train_0_dir)))\n",
    "\n",
    "train_1_dir = os.path.join(train_dir, '1')\n",
    "print ('Total training class 1 images:', len(os.listdir(train_1_dir)))\n",
    "\n",
    "train_2_dir = os.path.join(train_dir, '2')\n",
    "print ('Total training class 2 images:', len(os.listdir(train_2_dir)))\n",
    "\n",
    "train_3_dir = os.path.join(train_dir, '3')\n",
    "print ('Total training class 3 images:', len(os.listdir(train_3_dir)))\n",
    "\n",
    "train_4_dir = os.path.join(train_dir, '4')\n",
    "print ('Total training class 4 images:', len(os.listdir(train_4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dev class 0 images: 271\n",
      "Total dev class 1 images: 56\n",
      "Total dev class 2 images: 150\n",
      "Total dev class 3 images: 29\n",
      "Total dev class 4 images: 44\n"
     ]
    }
   ],
   "source": [
    "dev_0_dir = os.path.join(dev_dir, '0')\n",
    "print ('Total dev class 0 images:', len(os.listdir(dev_0_dir)))\n",
    "\n",
    "dev_1_dir = os.path.join(dev_dir, '1')\n",
    "print ('Total dev class 1 images:', len(os.listdir(dev_1_dir)))\n",
    "\n",
    "dev_2_dir = os.path.join(dev_dir, '2')\n",
    "print ('Total dev class 2 images:', len(os.listdir(dev_2_dir)))\n",
    "\n",
    "dev_3_dir = os.path.join(dev_dir, '3')\n",
    "print ('Total dev class 3 images:', len(os.listdir(dev_3_dir)))\n",
    "\n",
    "dev_4_dir = os.path.join(dev_dir, '4')\n",
    "print ('Total dev class 4 images:', len(os.listdir(dev_4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test class 0 images: 270\n",
      "Total test class 1 images: 55\n",
      "Total test class 2 images: 150\n",
      "Total test class 3 images: 29\n",
      "Total test class 4 images: 44\n"
     ]
    }
   ],
   "source": [
    "test_0_dir = os.path.join(test_dir, '0')\n",
    "print ('Total test class 0 images:', len(os.listdir(test_0_dir)))\n",
    "\n",
    "test_1_dir = os.path.join(test_dir, '1')\n",
    "print ('Total test class 1 images:', len(os.listdir(test_1_dir)))\n",
    "\n",
    "test_2_dir = os.path.join(test_dir, '2')\n",
    "print ('Total test class 2 images:', len(os.listdir(test_2_dir)))\n",
    "\n",
    "test_3_dir = os.path.join(test_dir, '3')\n",
    "print ('Total test class 3 images:', len(os.listdir(test_3_dir)))\n",
    "\n",
    "test_4_dir = os.path.join(test_dir, '4')\n",
    "print ('Total test class 4 images:', len(os.listdir(test_4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2564 images belonging to 5 classes.\n",
      "Found 550 images belonging to 5 classes.\n",
      "Found 548 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Rescale all images by 1./255 \n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "dev_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_dir,  # Source directory for the training images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size, shuffle = False,\n",
    "                # Since we use binary_crossentropy loss, we need binary labels\n",
    "                class_mode='categorical')\n",
    "\n",
    "# Flow dev images in batches using dev_datagen generator\n",
    "dev_generator = dev_datagen.flow_from_directory(\n",
    "                dev_dir, # Source directory for the dev images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size, shuffle = False,\n",
    "                class_mode='categorical')\n",
    "\n",
    "# Flow test images in batches using test_datagen generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                test_dir, # Source directory for the test images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size, shuffle = False,\n",
    "                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (image_size, image_size, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x64d932f90>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  keras.layers.GlobalAveragePooling2D(),\n",
    "  keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "model.load_weights(\"/Users/lucywang/Documents/Stanford/CS230Project/training224_0001Reg01FT2/cp.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset generators so images are presented in original order\n",
    "dev_generator.reset()\n",
    "test_generator.reset()\n",
    "train_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "predictions = model.predict_generator(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2564,)\n"
     ]
    }
   ],
   "source": [
    "pred_indices = np.squeeze(np.argmax(predictions,axis=1))\n",
    "print(pred_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "# True labels\n",
    "truth = np.zeros((270,)) \n",
    "truth = np.concatenate((truth,np.ones((55,))))\n",
    "truth = np.concatenate((truth,np.ones((150,))*2))\n",
    "truth = np.concatenate((truth,np.ones((29,))*3))\n",
    "truth = np.concatenate((truth,np.ones((44,))*4))\n",
    "truth = truth.astype(int)\n",
    "print(truth)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    quadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return 1.0 - numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8467750080891039\n"
     ]
    }
   ],
   "source": [
    "kappa = quadratic_weighted_kappa(pred_indices, truth, min_rating=None, max_rating=None)\n",
    "print(kappa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "print(\"TensorFlow version is \", tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "train_dir = os.path.join(base_dir, 'train_images_pre')\n",
    "dev_dir = os.path.join(base_dir, 'dev_images_pre')\n",
    "test_dir = os.path.join(base_dir, 'test_images_pre')\n",
    "\n",
    "train_0_dir = os.path.join(train_dir, '0')\n",
    "print ('Total training class 0 images:', len(os.listdir(train_0_dir)))\n",
    "\n",
    "train_1_dir = os.path.join(train_dir, '1')\n",
    "print ('Total training class 1 images:', len(os.listdir(train_1_dir)))\n",
    "\n",
    "train_2_dir = os.path.join(train_dir, '2')\n",
    "print ('Total training class 2 images:', len(os.listdir(train_2_dir)))\n",
    "\n",
    "train_3_dir = os.path.join(train_dir, '3')\n",
    "print ('Total training class 3 images:', len(os.listdir(train_3_dir)))\n",
    "\n",
    "train_4_dir = os.path.join(train_dir, '4')\n",
    "print ('Total training class 4 images:', len(os.listdir(train_4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_0_dir = os.path.join(dev_dir, '0')\n",
    "print ('Total dev class 0 images:', len(os.listdir(dev_0_dir)))\n",
    "\n",
    "dev_1_dir = os.path.join(dev_dir, '1')\n",
    "print ('Total dev class 1 images:', len(os.listdir(dev_1_dir)))\n",
    "\n",
    "dev_2_dir = os.path.join(dev_dir, '2')\n",
    "print ('Total dev class 2 images:', len(os.listdir(dev_2_dir)))\n",
    "\n",
    "dev_3_dir = os.path.join(dev_dir, '3')\n",
    "print ('Total dev class 3 images:', len(os.listdir(dev_3_dir)))\n",
    "\n",
    "dev_4_dir = os.path.join(dev_dir, '4')\n",
    "print ('Total dev class 4 images:', len(os.listdir(dev_4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_0_dir = os.path.join(test_dir, '0')\n",
    "print ('Total test class 0 images:', len(os.listdir(test_0_dir)))\n",
    "\n",
    "test_1_dir = os.path.join(test_dir, '1')\n",
    "print ('Total test class 1 images:', len(os.listdir(test_1_dir)))\n",
    "\n",
    "test_2_dir = os.path.join(test_dir, '2')\n",
    "print ('Total test class 2 images:', len(os.listdir(test_2_dir)))\n",
    "\n",
    "test_3_dir = os.path.join(test_dir, '3')\n",
    "print ('Total test class 3 images:', len(os.listdir(test_3_dir)))\n",
    "\n",
    "test_4_dir = os.path.join(test_dir, '4')\n",
    "print ('Total test class 4 images:', len(os.listdir(test_4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Rescale all images by 1./255 and apply image augmentation\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,rotation_range=360, horizontal_flip=True,vertical_flip=True)\n",
    "\n",
    "dev_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_dir,  # Source directory for the training images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                # Since we use binary_crossentropy loss, we need binary labels\n",
    "                class_mode='categorical')\n",
    "\n",
    "# Flow dev images in batches using dev_datagen generator\n",
    "dev_generator = dev_datagen.flow_from_directory(\n",
    "                dev_dir, # Source directory for the dev images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')\n",
    "\n",
    "# Flow test images in batches using test_datagen generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                test_dir, # Source directory for the test images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (image_size, image_size, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layers\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  keras.layers.GlobalAveragePooling2D(),\n",
    "  keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up callback\n",
    "checkpoint_path = \"Reg01/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "epochs = 1\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "dev_steps = dev_generator.n // batch_size\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              workers=4,\n",
    "                              validation_data=dev_generator,\n",
    "                              validation_steps=dev_steps, callbacks=[cp_callback],\n",
    "                              class_weight={0:641./1264., 1:641./259., 2:641./699., 3:641./135., 4:641./207.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracy and loss\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig('attempt1_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune by unfreezing weights\n",
    "base_model.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue to train model\n",
    "history_fine = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              workers=4,\n",
    "                              validation_data=dev_generator,\n",
    "                              validation_steps=dev_steps, callbacks=[cp_callback],\n",
    "                              class_weight={0:641./1264., 1:641./259., 2:641./699., 3:641./135., 4:641./207.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracy and loss\n",
    "acc = history_fine.history['categorical_accuracy']\n",
    "val_acc = history_fine.history['val_categorical_accuracy']\n",
    "\n",
    "loss = history_fine.history['loss']\n",
    "val_loss = history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig('attempt1_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
